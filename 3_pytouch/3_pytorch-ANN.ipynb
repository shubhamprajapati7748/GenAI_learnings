{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancel Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Raw URL of the CSV file\n",
    "url = \"https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/master/data.csv\"\n",
    "\n",
    "# Read the CSV into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id', 'Unnamed: 32'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "B    357\n",
       "M    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts() # B - No cancel , M - Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection  import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>15.320</td>\n",
       "      <td>17.27</td>\n",
       "      <td>103.20</td>\n",
       "      <td>713.3</td>\n",
       "      <td>0.13350</td>\n",
       "      <td>0.22840</td>\n",
       "      <td>0.24480</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.07596</td>\n",
       "      <td>...</td>\n",
       "      <td>17.73</td>\n",
       "      <td>22.66</td>\n",
       "      <td>119.80</td>\n",
       "      <td>928.8</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>0.45030</td>\n",
       "      <td>0.44290</td>\n",
       "      <td>0.22290</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>0.11910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>13.150</td>\n",
       "      <td>15.34</td>\n",
       "      <td>85.31</td>\n",
       "      <td>538.9</td>\n",
       "      <td>0.09384</td>\n",
       "      <td>0.08498</td>\n",
       "      <td>0.09293</td>\n",
       "      <td>0.03483</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.06207</td>\n",
       "      <td>...</td>\n",
       "      <td>14.77</td>\n",
       "      <td>20.50</td>\n",
       "      <td>97.67</td>\n",
       "      <td>677.3</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.22560</td>\n",
       "      <td>0.30090</td>\n",
       "      <td>0.09722</td>\n",
       "      <td>0.3849</td>\n",
       "      <td>0.08633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>10.260</td>\n",
       "      <td>12.22</td>\n",
       "      <td>65.75</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09996</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>0.01923</td>\n",
       "      <td>0.01968</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.06569</td>\n",
       "      <td>...</td>\n",
       "      <td>11.38</td>\n",
       "      <td>15.65</td>\n",
       "      <td>73.23</td>\n",
       "      <td>394.5</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.08615</td>\n",
       "      <td>0.06696</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.07722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>9.405</td>\n",
       "      <td>21.70</td>\n",
       "      <td>59.60</td>\n",
       "      <td>271.2</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.06159</td>\n",
       "      <td>0.02047</td>\n",
       "      <td>0.01257</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.06601</td>\n",
       "      <td>...</td>\n",
       "      <td>10.85</td>\n",
       "      <td>31.24</td>\n",
       "      <td>68.73</td>\n",
       "      <td>359.4</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.11930</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>0.03770</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.08304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6.981</td>\n",
       "      <td>13.43</td>\n",
       "      <td>43.79</td>\n",
       "      <td>143.5</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.07568</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>...</td>\n",
       "      <td>7.93</td>\n",
       "      <td>19.54</td>\n",
       "      <td>50.41</td>\n",
       "      <td>185.2</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.12020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2932</td>\n",
       "      <td>0.09382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>16.350</td>\n",
       "      <td>23.29</td>\n",
       "      <td>109.00</td>\n",
       "      <td>840.4</td>\n",
       "      <td>0.09742</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>0.18110</td>\n",
       "      <td>0.08773</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.06218</td>\n",
       "      <td>...</td>\n",
       "      <td>19.38</td>\n",
       "      <td>31.03</td>\n",
       "      <td>129.30</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.46650</td>\n",
       "      <td>0.70870</td>\n",
       "      <td>0.22480</td>\n",
       "      <td>0.4824</td>\n",
       "      <td>0.09614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>12.340</td>\n",
       "      <td>22.22</td>\n",
       "      <td>79.85</td>\n",
       "      <td>464.5</td>\n",
       "      <td>0.10120</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.05370</td>\n",
       "      <td>0.02822</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.06761</td>\n",
       "      <td>...</td>\n",
       "      <td>13.58</td>\n",
       "      <td>28.68</td>\n",
       "      <td>87.36</td>\n",
       "      <td>553.0</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>0.23380</td>\n",
       "      <td>0.16880</td>\n",
       "      <td>0.08194</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.09082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>13.170</td>\n",
       "      <td>18.22</td>\n",
       "      <td>84.28</td>\n",
       "      <td>537.3</td>\n",
       "      <td>0.07466</td>\n",
       "      <td>0.05994</td>\n",
       "      <td>0.04859</td>\n",
       "      <td>0.02870</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.05549</td>\n",
       "      <td>...</td>\n",
       "      <td>14.90</td>\n",
       "      <td>23.89</td>\n",
       "      <td>95.10</td>\n",
       "      <td>687.6</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.19650</td>\n",
       "      <td>0.18760</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.06925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>11.940</td>\n",
       "      <td>18.24</td>\n",
       "      <td>75.71</td>\n",
       "      <td>437.6</td>\n",
       "      <td>0.08261</td>\n",
       "      <td>0.04751</td>\n",
       "      <td>0.01972</td>\n",
       "      <td>0.01349</td>\n",
       "      <td>0.1868</td>\n",
       "      <td>0.06110</td>\n",
       "      <td>...</td>\n",
       "      <td>13.10</td>\n",
       "      <td>21.33</td>\n",
       "      <td>83.67</td>\n",
       "      <td>527.2</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>0.08906</td>\n",
       "      <td>0.09203</td>\n",
       "      <td>0.06296</td>\n",
       "      <td>0.2785</td>\n",
       "      <td>0.07408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "257       15.320         17.27          103.20      713.3          0.13350   \n",
       "154       13.150         15.34           85.31      538.9          0.09384   \n",
       "390       10.260         12.22           65.75      321.6          0.09996   \n",
       "416        9.405         21.70           59.60      271.2          0.10440   \n",
       "101        6.981         13.43           43.79      143.5          0.11700   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "370       16.350         23.29          109.00      840.4          0.09742   \n",
       "1         20.570         17.77          132.90     1326.0          0.08474   \n",
       "163       12.340         22.22           79.85      464.5          0.10120   \n",
       "464       13.170         18.22           84.28      537.3          0.07466   \n",
       "52        11.940         18.24           75.71      437.6          0.08261   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "257           0.22840         0.24480              0.12420         0.2398   \n",
       "154           0.08498         0.09293              0.03483         0.1822   \n",
       "390           0.07542         0.01923              0.01968         0.1800   \n",
       "416           0.06159         0.02047              0.01257         0.2025   \n",
       "101           0.07568         0.00000              0.00000         0.1930   \n",
       "..                ...             ...                  ...            ...   \n",
       "370           0.14970         0.18110              0.08773         0.2175   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "163           0.10150         0.05370              0.02822         0.1551   \n",
       "464           0.05994         0.04859              0.02870         0.1454   \n",
       "52            0.04751         0.01972              0.01349         0.1868   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "257                 0.07596  ...         17.73          22.66   \n",
       "154                 0.06207  ...         14.77          20.50   \n",
       "390                 0.06569  ...         11.38          15.65   \n",
       "416                 0.06601  ...         10.85          31.24   \n",
       "101                 0.07818  ...          7.93          19.54   \n",
       "..                      ...  ...           ...            ...   \n",
       "370                 0.06218  ...         19.38          31.03   \n",
       "1                   0.05667  ...         24.99          23.41   \n",
       "163                 0.06761  ...         13.58          28.68   \n",
       "464                 0.05549  ...         14.90          23.89   \n",
       "52                  0.06110  ...         13.10          21.33   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "257           119.80       928.8            0.1765            0.45030   \n",
       "154            97.67       677.3            0.1478            0.22560   \n",
       "390            73.23       394.5            0.1343            0.16500   \n",
       "416            68.73       359.4            0.1526            0.11930   \n",
       "101            50.41       185.2            0.1584            0.12020   \n",
       "..               ...         ...               ...                ...   \n",
       "370           129.30      1165.0            0.1415            0.46650   \n",
       "1             158.80      1956.0            0.1238            0.18660   \n",
       "163            87.36       553.0            0.1452            0.23380   \n",
       "464            95.10       687.6            0.1282            0.19650   \n",
       "52             83.67       527.2            0.1144            0.08906   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "257          0.44290               0.22290          0.3258   \n",
       "154          0.30090               0.09722          0.3849   \n",
       "390          0.08615               0.06696          0.2937   \n",
       "416          0.06141               0.03770          0.2872   \n",
       "101          0.00000               0.00000          0.2932   \n",
       "..               ...                   ...             ...   \n",
       "370          0.70870               0.22480          0.4824   \n",
       "1            0.24160               0.18600          0.2750   \n",
       "163          0.16880               0.08194          0.2268   \n",
       "464          0.18760               0.10450          0.2235   \n",
       "52           0.09203               0.06296          0.2785   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "257                  0.11910  \n",
       "154                  0.08633  \n",
       "390                  0.07722  \n",
       "416                  0.08304  \n",
       "101                  0.09382  \n",
       "..                       ...  \n",
       "370                  0.09614  \n",
       "1                    0.08902  \n",
       "163                  0.09082  \n",
       "464                  0.06925  \n",
       "52                   0.07408  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>14.640</td>\n",
       "      <td>16.85</td>\n",
       "      <td>94.21</td>\n",
       "      <td>666.0</td>\n",
       "      <td>0.08641</td>\n",
       "      <td>0.06698</td>\n",
       "      <td>0.051920</td>\n",
       "      <td>0.027910</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>0.05355</td>\n",
       "      <td>...</td>\n",
       "      <td>16.46</td>\n",
       "      <td>25.44</td>\n",
       "      <td>106.00</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.1142</td>\n",
       "      <td>0.20700</td>\n",
       "      <td>0.24370</td>\n",
       "      <td>0.07828</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.06596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>10.710</td>\n",
       "      <td>20.39</td>\n",
       "      <td>69.50</td>\n",
       "      <td>344.9</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.084480</td>\n",
       "      <td>0.028670</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.06862</td>\n",
       "      <td>...</td>\n",
       "      <td>11.69</td>\n",
       "      <td>25.21</td>\n",
       "      <td>76.51</td>\n",
       "      <td>410.4</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.25340</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0.08701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>12.180</td>\n",
       "      <td>14.08</td>\n",
       "      <td>77.25</td>\n",
       "      <td>461.4</td>\n",
       "      <td>0.07734</td>\n",
       "      <td>0.03212</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.05649</td>\n",
       "      <td>...</td>\n",
       "      <td>12.85</td>\n",
       "      <td>16.47</td>\n",
       "      <td>81.60</td>\n",
       "      <td>513.1</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>0.05332</td>\n",
       "      <td>0.04116</td>\n",
       "      <td>0.01852</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.06037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>21.370</td>\n",
       "      <td>15.10</td>\n",
       "      <td>141.30</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.15150</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.06183</td>\n",
       "      <td>...</td>\n",
       "      <td>22.69</td>\n",
       "      <td>21.84</td>\n",
       "      <td>152.10</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.28400</td>\n",
       "      <td>0.40240</td>\n",
       "      <td>0.19660</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>0.08666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>27.220</td>\n",
       "      <td>21.87</td>\n",
       "      <td>182.10</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>0.10940</td>\n",
       "      <td>0.19140</td>\n",
       "      <td>0.287100</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.05770</td>\n",
       "      <td>...</td>\n",
       "      <td>33.12</td>\n",
       "      <td>32.85</td>\n",
       "      <td>220.80</td>\n",
       "      <td>3216.0</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.40340</td>\n",
       "      <td>0.53400</td>\n",
       "      <td>0.26880</td>\n",
       "      <td>0.2856</td>\n",
       "      <td>0.08082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>18.010</td>\n",
       "      <td>20.56</td>\n",
       "      <td>118.40</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>0.077620</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.06077</td>\n",
       "      <td>...</td>\n",
       "      <td>21.53</td>\n",
       "      <td>26.06</td>\n",
       "      <td>143.40</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>0.1309</td>\n",
       "      <td>0.23270</td>\n",
       "      <td>0.25440</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.3251</td>\n",
       "      <td>0.07625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>11.610</td>\n",
       "      <td>16.02</td>\n",
       "      <td>75.46</td>\n",
       "      <td>408.2</td>\n",
       "      <td>0.10880</td>\n",
       "      <td>0.11680</td>\n",
       "      <td>0.070970</td>\n",
       "      <td>0.044970</td>\n",
       "      <td>0.1886</td>\n",
       "      <td>0.06320</td>\n",
       "      <td>...</td>\n",
       "      <td>12.64</td>\n",
       "      <td>19.67</td>\n",
       "      <td>81.93</td>\n",
       "      <td>475.7</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.21700</td>\n",
       "      <td>0.23020</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2787</td>\n",
       "      <td>0.07427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>9.465</td>\n",
       "      <td>21.01</td>\n",
       "      <td>60.11</td>\n",
       "      <td>269.4</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>0.021720</td>\n",
       "      <td>0.015040</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.06899</td>\n",
       "      <td>...</td>\n",
       "      <td>10.41</td>\n",
       "      <td>31.56</td>\n",
       "      <td>67.03</td>\n",
       "      <td>330.7</td>\n",
       "      <td>0.1548</td>\n",
       "      <td>0.16640</td>\n",
       "      <td>0.09412</td>\n",
       "      <td>0.06517</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.09211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.06811</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>10.440</td>\n",
       "      <td>15.46</td>\n",
       "      <td>66.62</td>\n",
       "      <td>329.6</td>\n",
       "      <td>0.10530</td>\n",
       "      <td>0.07722</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.012160</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.06450</td>\n",
       "      <td>...</td>\n",
       "      <td>11.52</td>\n",
       "      <td>19.80</td>\n",
       "      <td>73.47</td>\n",
       "      <td>395.4</td>\n",
       "      <td>0.1341</td>\n",
       "      <td>0.11530</td>\n",
       "      <td>0.02639</td>\n",
       "      <td>0.04464</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>0.08269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "486       14.640         16.85           94.21      666.0          0.08641   \n",
       "269       10.710         20.39           69.50      344.9          0.10820   \n",
       "316       12.180         14.08           77.25      461.4          0.07734   \n",
       "372       21.370         15.10          141.30     1386.0          0.10010   \n",
       "180       27.220         21.87          182.10     2250.0          0.10940   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "492       18.010         20.56          118.40     1007.0          0.10010   \n",
       "422       11.610         16.02           75.46      408.2          0.10880   \n",
       "66         9.465         21.01           60.11      269.4          0.10440   \n",
       "20        13.080         15.71           85.63      520.0          0.10750   \n",
       "226       10.440         15.46           66.62      329.6          0.10530   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "486           0.06698        0.051920             0.027910         0.1409   \n",
       "269           0.12890        0.084480             0.028670         0.1668   \n",
       "316           0.03212        0.011230             0.005051         0.1673   \n",
       "372           0.15150        0.193200             0.125500         0.1973   \n",
       "180           0.19140        0.287100             0.187800         0.1800   \n",
       "..                ...             ...                  ...            ...   \n",
       "492           0.12890        0.117000             0.077620         0.2116   \n",
       "422           0.11680        0.070970             0.044970         0.1886   \n",
       "66            0.07773        0.021720             0.015040         0.1717   \n",
       "20            0.12700        0.045680             0.031100         0.1967   \n",
       "226           0.07722        0.006643             0.012160         0.1788   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "486                 0.05355  ...         16.46          25.44   \n",
       "269                 0.06862  ...         11.69          25.21   \n",
       "316                 0.05649  ...         12.85          16.47   \n",
       "372                 0.06183  ...         22.69          21.84   \n",
       "180                 0.05770  ...         33.12          32.85   \n",
       "..                      ...  ...           ...            ...   \n",
       "492                 0.06077  ...         21.53          26.06   \n",
       "422                 0.06320  ...         12.64          19.67   \n",
       "66                  0.06899  ...         10.41          31.56   \n",
       "20                  0.06811  ...         14.50          20.49   \n",
       "226                 0.06450  ...         11.52          19.80   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "486           106.00       831.0            0.1142            0.20700   \n",
       "269            76.51       410.4            0.1335            0.25500   \n",
       "316            81.60       513.1            0.1001            0.05332   \n",
       "372           152.10      1535.0            0.1192            0.28400   \n",
       "180           220.80      3216.0            0.1472            0.40340   \n",
       "..               ...         ...               ...                ...   \n",
       "492           143.40      1426.0            0.1309            0.23270   \n",
       "422            81.93       475.7            0.1415            0.21700   \n",
       "66             67.03       330.7            0.1548            0.16640   \n",
       "20             96.09       630.5            0.1312            0.27760   \n",
       "226            73.47       395.4            0.1341            0.11530   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "486          0.24370               0.07828          0.2455   \n",
       "269          0.25340               0.08600          0.2605   \n",
       "316          0.04116               0.01852          0.2293   \n",
       "372          0.40240               0.19660          0.2730   \n",
       "180          0.53400               0.26880          0.2856   \n",
       "..               ...                   ...             ...   \n",
       "492          0.25440               0.14890          0.3251   \n",
       "422          0.23020               0.11050          0.2787   \n",
       "66           0.09412               0.06517          0.2878   \n",
       "20           0.18900               0.07283          0.3184   \n",
       "226          0.02639               0.04464          0.2615   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "486                  0.06596  \n",
       "269                  0.08701  \n",
       "316                  0.06037  \n",
       "372                  0.08666  \n",
       "180                  0.08082  \n",
       "..                       ...  \n",
       "492                  0.07625  \n",
       "422                  0.07427  \n",
       "66                   0.09211  \n",
       "20                   0.08183  \n",
       "226                  0.08269  \n",
       "\n",
       "[114 rows x 30 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486    B\n",
       "269    B\n",
       "316    B\n",
       "372    M\n",
       "180    M\n",
       "      ..\n",
       "492    M\n",
       "422    B\n",
       "66     B\n",
       "20     B\n",
       "226    B\n",
       "Name: diagnosis, Length: 114, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257    M\n",
       "154    B\n",
       "390    B\n",
       "416    B\n",
       "101    B\n",
       "      ..\n",
       "370    M\n",
       "1      M\n",
       "163    B\n",
       "464    B\n",
       "52     B\n",
       "Name: diagnosis, Length: 455, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31119971, -0.48014723,  0.44245118, ...,  1.65552669,\n",
       "         0.59144541,  1.97062963],\n",
       "       [-0.31892574, -0.92094562, -0.31275131, ..., -0.25574671,\n",
       "         1.54514423,  0.16156141],\n",
       "       [-1.15812508, -1.63353162, -1.13845063, ..., -0.7159244 ,\n",
       "         0.07344657, -0.34135625],\n",
       "       ...,\n",
       "       [-0.55413386,  0.65039786, -0.54323793, ..., -0.48811667,\n",
       "        -1.00612113,  0.40943191],\n",
       "       [-0.31311814, -0.26317393, -0.35623139, ..., -0.14503641,\n",
       "        -1.05937335, -0.78134019],\n",
       "       [-0.67028602, -0.25860607, -0.71800251, ..., -0.77675424,\n",
       "        -0.17183638, -0.51469998]], shape=(455, 30))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11374104, -0.57607227,  0.06295032, ..., -0.54377597,\n",
       "        -0.70435856, -0.96296467],\n",
       "       [-1.0274539 ,  0.23243877, -0.98014938, ..., -0.42637439,\n",
       "        -0.46230302,  0.19910082],\n",
       "       [-0.60059473, -1.20872073, -0.65299347, ..., -1.4525737 ,\n",
       "        -0.96577854, -1.27156069],\n",
       "       ...,\n",
       "       [-1.38897749,  0.37404239, -1.37653571, ..., -0.74314575,\n",
       "        -0.02176195,  0.48064638],\n",
       "       [-0.33925237, -0.83644023, -0.29924294, ..., -0.62665662,\n",
       "         0.47203135, -0.08686114],\n",
       "       [-1.10585661, -0.89353847, -1.10172474, ..., -1.05535488,\n",
       "        -0.44616599, -0.03938483]], shape=(114, 30))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X_train_tensor = torch.from_numpy(X_train_scaled.astype(np.float32))\n",
    "X_test_tensor = torch.from_numpy(X_test_scaled.astype(np.float32))\n",
    "y_train_tensor = torch.from_numpy(y_train_encoded.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(y_test_encoded.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3112, -0.4801,  0.4425,  ...,  1.6555,  0.5914,  1.9706],\n",
       "        [-0.3189, -0.9209, -0.3128,  ..., -0.2557,  1.5451,  0.1616],\n",
       "        [-1.1581, -1.6335, -1.1385,  ..., -0.7159,  0.0734, -0.3414],\n",
       "        ...,\n",
       "        [-0.5541,  0.6504, -0.5432,  ..., -0.4881, -1.0061,  0.4094],\n",
       "        [-0.3131, -0.2632, -0.3562,  ..., -0.1450, -1.0594, -0.7813],\n",
       "        [-0.6703, -0.2586, -0.7180,  ..., -0.7768, -0.1718, -0.5147]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1137, -0.5761,  0.0630,  ..., -0.5438, -0.7044, -0.9630],\n",
       "        [-1.0275,  0.2324, -0.9801,  ..., -0.4264, -0.4623,  0.1991],\n",
       "        [-0.6006, -1.2087, -0.6530,  ..., -1.4526, -0.9658, -1.2716],\n",
       "        ...,\n",
       "        [-1.3890,  0.3740, -1.3765,  ..., -0.7431, -0.0218,  0.4806],\n",
       "        [-0.3393, -0.8364, -0.2992,  ..., -0.6267,  0.4720, -0.0869],\n",
       "        [-1.1059, -0.8935, -1.1017,  ..., -1.0554, -0.4462, -0.0394]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
       "        1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1 ## Hyperparameter\n",
    "epochs = 20 ## One forward + One Backward = 1 Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function \n",
    "import torch.nn as nn \n",
    "loss_funtion = nn.BCELoss() # Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self, new_feature):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(new_feature, 3) # Hidden layer with 3 neuron\n",
    "        self.relu = nn.ReLU() ## To apply Relu on Hidden layer\n",
    "        self.linear2 = nn.Linear(3, 1) # Ouput layer\n",
    "        self.sigmoid = nn.Sigmoid() # To apply Sigmoid on output layer\n",
    "\n",
    "    def forward(self, features):\n",
    "        output = self.linear1(features)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear2(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNeuralNetwork(\n",
       "  (linear1): Linear(in_features=30, out_features=3, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (linear2): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleNeuralNetwork(30)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizer \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.6760492920875549\n",
      "Epoch: 2, Loss: 0.6620670557022095\n",
      "Epoch: 3, Loss: 0.6482400298118591\n",
      "Epoch: 4, Loss: 0.6343316435813904\n",
      "Epoch: 5, Loss: 0.6202483177185059\n",
      "Epoch: 6, Loss: 0.6059899926185608\n",
      "Epoch: 7, Loss: 0.5916560888290405\n",
      "Epoch: 8, Loss: 0.57710200548172\n",
      "Epoch: 9, Loss: 0.5620502829551697\n",
      "Epoch: 10, Loss: 0.5463389158248901\n",
      "Epoch: 11, Loss: 0.5304031372070312\n",
      "Epoch: 12, Loss: 0.5140149593353271\n",
      "Epoch: 13, Loss: 0.4974101781845093\n",
      "Epoch: 14, Loss: 0.48077577352523804\n",
      "Epoch: 15, Loss: 0.46414467692375183\n",
      "Epoch: 16, Loss: 0.4475858211517334\n",
      "Epoch: 17, Loss: 0.43127933144569397\n",
      "Epoch: 18, Loss: 0.4152878522872925\n",
      "Epoch: 19, Loss: 0.3996724486351013\n",
      "Epoch: 20, Loss: 0.3845237195491791\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    ## Forward pass \n",
    "    y_pred = model(X_train_tensor)\n",
    "\n",
    "    ## loss calculation\n",
    "    loss = loss_funtion(y_pred, y_train_tensor.view(-1,1)) ## view -> to convert into 1D array\n",
    "\n",
    "    ## To calculate Gradient -> Optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    ## Backward Propogation\n",
    "    loss.backward()\n",
    "\n",
    "    ## Paramater updation\n",
    "    optimizer.step()\n",
    "\n",
    "    ## Printing Epoch and loss\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.5492458939552307\n"
     ]
    }
   ],
   "source": [
    "## Calculating Accuracy\n",
    "with torch.no_grad(): # no_grad -> No need to calculate the Gradient\n",
    "    y_pred = model.forward(X_test_tensor)\n",
    "    y_pred = (y_pred > 0.5).float()\n",
    "    accuracy = (y_pred == y_test_tensor).float().mean()\n",
    "    print(f\"accuracy : {accuracy.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
